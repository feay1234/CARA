{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTSKO2yWp1aG"
   },
   "source": [
    "\n",
    "# Contextual Attention Recurrent Architecture for Context-aware Venue Recommendation (CARA)\n",
    "\n",
    "This is our implementation of CARA architecture. \n",
    "\n",
    "**Please cite our SIGIR'18 paper if you use our codes. Thanks!**\n",
    "\n",
    "Contextual Attention Recurrent Architecture for Context-aware Venue Recommendation. Jarana Manotumruksa, Craig Macdonald and Iadh Ounis. In Proceedings of SIGIR 2018.\n",
    "\n",
    "https://dl.acm.org/doi/10.1145/3209978.3210042\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N9-ApHkqsCEG"
   },
   "source": [
    "CARA was implemented using Keras version: 1.2.2. Please note that Keras 2 is not compatible with our source code since some features on Keras 1.2.2 were discarded from Keras 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_3tjT6aRPK1D",
    "outputId": "be636ab8-c039-45ce-bbda-9867e5fe09ab"
   },
   "outputs": [],
   "source": [
    "!pip install keras==1.2.2 theano==0.9.0 pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7VaviU800tah",
    "outputId": "b19ee457-9c1f-4f19-c7a6-960312969608"
   },
   "outputs": [],
   "source": [
    "import os; os.environ['KERAS_BACKEND'] = 'theano'\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Embedding, Input, merge, SimpleRNN, Activation, Dense, Flatten, GlobalAveragePooling1D, GRU, LSTM, Recurrent, initializations, activations, regularizers, time_distributed_dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.regularizers import l2\n",
    "from keras.engine import InputSpec\n",
    "from keras import backend as K\n",
    "\n",
    "import theano as theano\n",
    "from theano.scalar.sharedvar import shared\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jpvhJe7w0lFJ"
   },
   "outputs": [],
   "source": [
    "def identity_loss(y_true, y_pred):\n",
    "    return K.mean(y_pred - 0 * y_true)\n",
    "\n",
    "class CARA(GRU):\n",
    "    def __init__(self, output_dim,\n",
    "                 init='glorot_uniform', inner_init='orthogonal',\n",
    "                 activation='tanh', inner_activation='hard_sigmoid',\n",
    "                 W_regularizer=None, U_regularizer=None, b_regularizer=None,\n",
    "                 dropout_W=0., dropout_U=0., **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        self.init = initializations.get(init)\n",
    "        self.inner_init = initializations.get(inner_init)\n",
    "        self.activation = activations.get(activation)\n",
    "        self.inner_activation = activations.get(inner_activation)\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.U_regularizer = regularizers.get(U_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "        self.dropout_W = dropout_W\n",
    "        self.dropout_U = dropout_U\n",
    "\n",
    "        if self.dropout_W or self.dropout_U:\n",
    "            self.uses_learning_phase = True\n",
    "        super(GRU, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_spec = [InputSpec(shape=input_shape)]\n",
    "        self.input_dim = 10\n",
    "\n",
    "        if self.stateful:\n",
    "            self.reset_states()\n",
    "        else:\n",
    "            # initial states: all-zero tensor of shape (output_dim)\n",
    "            self.states = [None]\n",
    "\n",
    "        # W and b are the transition matrix between the latent factors of venues and the corresponding bias, respectively.\n",
    "        # U is is a recurrent connection weight matrix that captures sequential signals between every two adjacent hidden states.\n",
    "\n",
    "        # W_z, U_z and b_z are the set of parameters of the update gate (see Equation (2)).\n",
    "        self.W_z = self.add_weight((self.input_dim, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_W_z'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "        self.U_z = self.add_weight((self.output_dim, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_U_z'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "        self.b_z = self.add_weight((self.output_dim,),\n",
    "                                   initializer='zero',\n",
    "                                   name='{}_b_z'.format(self.name),\n",
    "                                   regularizer=self.b_regularizer)\n",
    "        \n",
    "        # W_r, U_r and b_r are the set of parameters of the reset gate (see Equation (2)).\n",
    "        self.W_r = self.add_weight((self.input_dim, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_W_r'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "        self.U_r = self.add_weight((self.output_dim, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_U_r'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "        self.b_r = self.add_weight((self.output_dim,),\n",
    "                                   initializer='zero',\n",
    "                                   name='{}_b_r'.format(self.name),\n",
    "                                   regularizer=self.b_regularizer)\n",
    "        \n",
    "\n",
    "        # W_h, U_h and b_h are the set of parameters of the candidate hidden state (see Equation (3)).\n",
    "\n",
    "        self.W_h = self.add_weight((self.input_dim, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_W_h'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "        self.U_h = self.add_weight((self.output_dim, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_U_h'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "        self.b_h = self.add_weight((self.output_dim,),\n",
    "                                   initializer='zero',\n",
    "                                   name='{}_b_h'.format(self.name),\n",
    "                                   regularizer=self.b_regularizer)\n",
    "\n",
    "        # A_h, b_a_h and A_u, b_a_u are weight parameters and corresponding bias of Contextual Attention Gate (CAG) (see Equation (12)).\n",
    "        self.A_h = self.add_weight((self.output_dim, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_A_h'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "        self.A_u = self.add_weight((self.output_dim, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_A_u'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "\n",
    "        self.b_a_h = self.add_weight((self.output_dim,),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b_a_h'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer)\n",
    "        self.b_a_u = self.add_weight((self.output_dim,),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b_a_u'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer)\n",
    "\n",
    "        # W_g, U_g and b_g are the set of parameters of our proposed time-based gate (see Equation (16)).\n",
    "        self.W_t = self.add_weight((self.input_dim, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_W_t'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "        self.U_t = self.add_weight((1, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_U_t'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "        self.b_t = self.add_weight((self.output_dim,),\n",
    "                                   initializer='zero',\n",
    "                                   name='{}_b_t'.format(self.name),\n",
    "                                   regularizer=self.b_regularizer)\n",
    "\n",
    "        # W_g, U_g and b_g are the set of parameters of our proposed spatial-based gate (see Equation (17)).\n",
    "        self.W_g = self.add_weight((self.input_dim, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_W_g'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "        self.U_g = self.add_weight((1, self.output_dim),\n",
    "                                   initializer=self.init,\n",
    "                                   name='{}_U_g'.format(self.name),\n",
    "                                   regularizer=self.W_regularizer)\n",
    "        self.b_g = self.add_weight((self.output_dim,),\n",
    "                                   initializer='zero',\n",
    "                                   name='{}_b_g'.format(self.name),\n",
    "                                   regularizer=self.b_regularizer)\n",
    "\n",
    "\n",
    "\n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "            del self.initial_weights\n",
    "        self.built = True\n",
    "\n",
    "    def preprocess_input(self, x):\n",
    "        return x\n",
    "\n",
    "    def step(self, x, states):\n",
    "        h_tm1 = states[0]  # previous memory\n",
    "        B_U = states[1]  # dropout matrices for recurrent units\n",
    "        B_W = states[2]\n",
    "\n",
    "        u = x[:, self.output_dim: 2 * self.output_dim]\n",
    "        t = x[:, 2 * self.output_dim: (2 * self.output_dim) + 1]\n",
    "        g = x[:, (2 * self.output_dim) + 1:]\n",
    "        x = x[:, :self.output_dim]\n",
    "\n",
    "        t = self.inner_activation(K.dot(t, self.U_t))\n",
    "        g = self.inner_activation(K.dot(g, self.U_g))\n",
    "#       Time-based gate\n",
    "        T = self.inner_activation(K.dot(x, self.W_t) + t + self.b_t)\n",
    "#       Geo-based gate\n",
    "        G = self.inner_activation(K.dot(x, self.W_g) + g + self.b_g)\n",
    "\n",
    "#       Contextual Attention Gate\n",
    "        a = self.inner_activation(\n",
    "            K.dot(h_tm1, self.A_h) + K.dot(u, self.A_u) + self.b_a_h + self.b_a_u)\n",
    "\n",
    "        x_z = K.dot(x, self.W_z) + self.b_z\n",
    "        x_r = K.dot(x, self.W_r) + self.b_r\n",
    "        x_h = K.dot(x, self.W_h) + self.b_h\n",
    "\n",
    "        u_z_ = K.dot((1 - a) * u, self.W_z) + self.b_z\n",
    "        u_r_ = K.dot((1 - a) * u, self.W_r) + self.b_r\n",
    "        u_h_ = K.dot((1 - a) * u, self.W_h) + self.b_h\n",
    "\n",
    "        u_z = K.dot(a * u, self.W_z) + self.b_z\n",
    "        u_r = K.dot(a * u, self.W_r) + self.b_r\n",
    "        u_h = K.dot(a * u, self.W_h) + self.b_h\n",
    "\n",
    "#       update gate\n",
    "        z = self.inner_activation(x_z + K.dot(h_tm1, self.U_z) + u_z)\n",
    "#       reset gate\n",
    "        r = self.inner_activation(x_r + K.dot(h_tm1, self.U_r) + u_r)\n",
    "#       hidden state\n",
    "        hh = self.activation(x_h + K.dot(r * T * G * h_tm1, self.U_h) + u_h)\n",
    "\n",
    "        h = z * h_tm1 + (1 - z) * hh\n",
    "        h = (1 + u_z_ + u_r_ + u_h_) * h\n",
    "        return h, [h]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ArwhFJOw0pcR"
   },
   "outputs": [],
   "source": [
    "def init_normal(shape, name=None):\n",
    "    return initializations.normal(shape, scale=0.01, name=name)\n",
    "\n",
    "def bpr_triplet_loss(X):\n",
    "    positive_item_latent, negative_item_latent = X\n",
    "\n",
    "    reg = 0\n",
    "\n",
    "    loss = 1 - K.log(K.sigmoid(\n",
    "        K.sum(positive_item_latent, axis=-1, keepdims=True) -\n",
    "        K.sum(negative_item_latent, axis=-1, keepdims=True))) - reg\n",
    "\n",
    "    return loss\n",
    "\n",
    "# Context-Aware Venue Recommendation with pairwise ranking function\n",
    "class Recommender():\n",
    "    def __init__(self, num_users, num_items, num_times, latent_dim, maxVenue=5):\n",
    "\n",
    "        self.maxVenue = maxVenue\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "#       Inputs\n",
    "        self.user_input = Input(shape=(1,), dtype='int32', name='user_input')\n",
    "        self.checkins_input = Input(shape=(self.maxVenue,), dtype='int32', name='venue_input')\n",
    "        self.neg_checkins_input = Input(shape=(self.maxVenue,), dtype='int32', name='neg_venue_input')\n",
    "        self.time_input = Input(shape=(self.maxVenue,), dtype='int32', name='time_input')\n",
    "        self.gap_time_input = Input(shape=(self.maxVenue, 1,), dtype='float32', name='time_interval_input')\n",
    "        \n",
    "        self.u_embedding = Embedding(input_dim=num_users, output_dim=latent_dim, name='user_embedding', \n",
    "                                     init=init_normal)\n",
    "        self.v_embedding = Embedding(input_dim=num_items, output_dim=latent_dim, name='venue_embedding',\n",
    "                                     init=init_normal) \n",
    "        self.t_embedding = Embedding(input_dim=num_times, output_dim=latent_dim, name='time_embedding',\n",
    "                                     init=init_normal) \n",
    "\n",
    "\n",
    "#       User latent factor\n",
    "        self.u_latent = Flatten()(self.u_embedding(self.user_input))\n",
    "        self.t_latent = Flatten()(self.t_embedding(self.time_input))\n",
    "\n",
    "        rnn_input = merge(\n",
    "                [self.v_embedding(self.checkins_input), self.t_embedding(self.time_input), self.gap_time_input],\n",
    "                mode=\"concat\")\n",
    "        neg_rnn_input = merge(\n",
    "                [self.v_embedding(self.neg_checkins_input), self.t_embedding(self.time_input), self.gap_time_input],\n",
    "                mode=\"concat\")\n",
    "\n",
    "        \n",
    "        self.pos_distance_input = Input(shape=(self.maxVenue, 1,), dtype='float32', name='pos_distance_input')\n",
    "        self.neg_distance_input = Input(shape=(self.maxVenue, 1,), dtype='float32', name='neg_distance_input')\n",
    "        rnn_input = merge([rnn_input, self.pos_distance_input], mode=\"concat\")\n",
    "        neg_rnn_input = merge([neg_rnn_input, self.neg_distance_input], mode=\"concat\")\n",
    "\n",
    "\n",
    "        self.rnn = Sequential()\n",
    "\n",
    "        self.rnn.add(\n",
    "                        CARA(latent_dim, input_shape=(self.maxVenue, (self.latent_dim * 2) + 2,), unroll=True))\n",
    "        \n",
    "\n",
    "        self.checkins_emb = self.rnn(rnn_input)\n",
    "        self.neg_checkins_emb = self.rnn(neg_rnn_input)\n",
    "\n",
    "        pred = merge([self.checkins_emb, self.u_latent], mode=\"dot\")\n",
    "        neg_pred = merge([self.neg_checkins_emb, self.u_latent], mode=\"dot\")\n",
    "\n",
    "        \n",
    "        INPUT = [self.user_input, self.time_input, self.gap_time_input, self.pos_distance_input,\n",
    "                 self.neg_distance_input, self.checkins_input,\n",
    "                 self.neg_checkins_input]\n",
    "\n",
    "        loss = merge([pred, neg_pred], mode=bpr_triplet_loss, name='loss', output_shape=(1,))\n",
    "        self.model = Model(input=INPUT, output=loss)\n",
    "        self.model.compile(optimizer=Adam(), loss=identity_loss)\n",
    "        \n",
    "\n",
    "    def rank(self, uid, hist_venues, hist_times, hist_time_gap, hist_distances):\n",
    "        \n",
    "        u_latent = self.model.get_layer('user_embedding').get_weights()[0][uid]\n",
    "        v_latent = self.model.get_layer('venue_embedding').get_weights()[0][hist_venues]\n",
    "        t_latent = self.model.get_layer('time_embedding').get_weights()[0][hist_times]\n",
    "        rnn_input = np.concatenate([t_latent, hist_time_gap], axis=-1)\n",
    "        rnn_input = np.concatenate([rnn_input, hist_distances], axis=-1)\n",
    "\n",
    "        rnn_input = np.concatenate([v_latent, rnn_input], axis=-1)\n",
    "\n",
    "        dynamic_latent = self.rnn.predict(rnn_input)\n",
    "        scores = np.dot(dynamic_latent, u_latent)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B554MCWZwXIs"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-iA0sgpDZz-n",
    "outputId": "3a57522a-ad38-431e-fd93-f53b52eba7c4"
   },
   "outputs": [],
   "source": [
    "# Download Brightkite dataset\n",
    "!wget https://snap.stanford.edu/data/loc-brightkite_totalCheckins.txt.gz\n",
    "!gzip -d loc-brightkite_totalCheckins.txt.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GFQfGP0JbQLM"
   },
   "source": [
    "**File format of Brightkite dataset**\n",
    "\n",
    "[user]\t[check-in time]\t\t[latitude]\t[longitude]\t[location id]\n",
    "\n",
    "58186   2008-12-03T21:09:14Z    39.633321       -105.317215     ee8b88dea22411\n",
    "\n",
    "58186   2008-11-30T22:30:12Z    39.633321       -105.317215     ee8b88dea22411\n",
    "\n",
    "58186   2008-11-28T17:55:04Z    -13.158333      -72.531389      e6e86be2a22411"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eJfpfPMwdpjm"
   },
   "outputs": [],
   "source": [
    "# Utils\n",
    "def time_encoder(t):\n",
    "    date_format = \"%Y-%m-%dT%H:%M:%SZ\"\n",
    "    time = datetime.strptime(t, date_format)\n",
    "\n",
    "    week = time.weekday()\n",
    "    hour = time.hour\n",
    "    month = time.month\n",
    "    return int(format(month, 'b') + format(week, 'b') + format(hour, 'b'), 2)\n",
    "\n",
    "def get_time_interval(t1, t2, mode=\"hour\", enableRound=False):\n",
    "    date_format = \"%Y-%m-%dT%H:%M:%SZ\"\n",
    "    time1  = datetime.strptime(t1, date_format)\n",
    "    date_format = \"%Y-%m-%dT%H:%M:%SZ\"\n",
    "    time2  = datetime.strptime(t2, date_format)\n",
    "    diff = time2 - time1\n",
    "\n",
    "    if mode == \"hour\":\n",
    "        gap =  (diff.days*24) + (diff.seconds) / 3600\n",
    "    elif mode == \"minute\":\n",
    "        gap = (diff.days*24*60) + (diff.seconds) / 60\n",
    "    else:\n",
    "        gap = (diff.days*24*60*60) + diff.seconds\n",
    "\n",
    "    if enableRound:\n",
    "        gap = int(round(gap))\n",
    "    return gap\n",
    "\n",
    "def get_distance(lat1, lng1, lat2, lng2):\n",
    "\n",
    "    # coords_1 = (lat1, lng1)\n",
    "    # coords_2 = (lat2, lng2)\n",
    "    #\n",
    "    # return geopy.distance.vincenty(coords_1, coords_2).km\n",
    "\n",
    "    # approximate radius of earth in km\n",
    "    R = 6373.0\n",
    "\n",
    "    lat1 = radians(lat1)\n",
    "    lon1 = radians(lng1)\n",
    "    lat2 = radians(lat2)\n",
    "    lon2 = radians(lng2)\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    distance = int(R * c)\n",
    "    # return int(distance/4)\n",
    "    return distance\n",
    "\n",
    "def generate_training_instances():\n",
    "    x_users, x_times, x_time_intervals, x_pos_checkins, x_neg_checkins, x_pos_distances, x_neg_distances = [], [], [], [], [], [], []\n",
    "    for uid, group in df.groupby('uid'):\n",
    "        \n",
    "        visits = group.vid.tolist()\n",
    "        lats = group.lat.tolist()\n",
    "        lngs = group.lng.tolist()\n",
    "        times = group.tid.tolist()\n",
    "\n",
    "        timestamp = group.time.tolist()\n",
    "        pos_distances = [0] + [get_distance(lats[i], lngs[i], lats[i + 1], lngs[i + 1]) for i in range(len(visits) - 1)]\n",
    "        time_intervals = [0] + [get_time_interval(timestamp[i], timestamp[i + 1]) for i in range(len(timestamp) - 1)]\n",
    "\n",
    "        sub_checkins, sub_times, sub_distances, sub_time_intervals = [], [], [], []\n",
    "\n",
    "        for i in range(len(visits)):\n",
    "            sub_checkins.append(visits[i])\n",
    "            sub_times.append(times[i])\n",
    "            sub_distances.append(pos_distances[i])\n",
    "            sub_time_intervals.append(time_intervals[i])\n",
    "\n",
    "            x_users.append(uid)\n",
    "            x_times.extend(sequence.pad_sequences([sub_times[:]], maxlen=maxVenue))\n",
    "\n",
    "            x_pos_checkins.extend(sequence.pad_sequences([sub_checkins[:]], maxlen=maxVenue))\n",
    "            x_pos_distances.extend(\n",
    "                      np.expand_dims(sequence.pad_sequences([sub_distances[:]], maxlen=maxVenue), -1))\n",
    "            x_time_intervals.extend(\n",
    "                      np.expand_dims(sequence.pad_sequences([sub_time_intervals[:]], maxlen=maxVenue), -1))\n",
    "\n",
    "            # Random negative venue, the user has never visited before\n",
    "            j = np.random.randint(vNum)\n",
    "            while j in visits or j == 0:\n",
    "                j = np.random.randint(vNum)\n",
    "\n",
    "            # replace the last checkin with the negative venue\n",
    "            tmp = sub_checkins[:]\n",
    "            tmp[-1] = j\n",
    "            x_neg_checkins.extend(sequence.pad_sequences([tmp[:]], maxlen=maxVenue))\n",
    "\n",
    "            # calculate the distance between the previous visited venue and the negative venue\n",
    "            if len(sub_distances) > 1:\n",
    "                tmp = sub_distances[:]\n",
    "                j_coor = vid2latlng[j]\n",
    "                tmp[-1] = get_distance(lats[i - 1], lngs[i - 1], j_coor[0], j_coor[1])\n",
    "                x_neg_distances.extend(\n",
    "                    np.expand_dims(sequence.pad_sequences([tmp[:]], maxlen=maxVenue), -1))\n",
    "            else:\n",
    "                x_neg_distances.extend(\n",
    "                np.expand_dims(sequence.pad_sequences([sub_distances[:]], maxlen=maxVenue), -1))\n",
    "    return [np.array(x_users), np.array(x_times), np.array(x_time_intervals), np.array(x_pos_distances), np.array(x_neg_distances), np.array(x_pos_checkins), np.array(x_neg_checkins)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wdjuj8OQwjFP"
   },
   "source": [
    "# For demonstration, we only consider the first 100,000 rows.\n",
    "# Please remove \"nrows=100000\" for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oOkRqGgua1U3"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"loc-brightkite_totalCheckins.txt\", nrows=100000, sep=\"\\t\", names=['uid', 'time', 'lat', 'lng', 'vid'])\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ONbSzXy6doBg"
   },
   "outputs": [],
   "source": [
    "# indexing user, venue and time. First index starts at 1\n",
    "user2id = {i:idx+1 for idx, i in enumerate(df.uid.unique())}\n",
    "df['uid'] = [user2id[i] for i in df['uid'].tolist()]\n",
    "\n",
    "venue2id = {i:idx+1 for idx, i in enumerate(df.vid.unique())}\n",
    "df['vid'] = [venue2id[i] for i in df['vid'].tolist()]\n",
    "\n",
    "df['tid'] = [time_encoder(i) for i in df['time'].tolist()]\n",
    "time2id = {i:idx+1 for idx, i in enumerate(df.tid.unique())}\n",
    "df['tid'] = [time2id[i] for i in df['tid'].tolist()]\n",
    "\n",
    "# venues' location\n",
    "vid2latlng = {int(row['vid']): (row['lat'], row['lng']) for idx, row in df[['vid', 'lat', 'lng']].drop_duplicates().iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "id": "6E2JZ2G6cx_0",
    "outputId": "0e09c8e1-af53-4329-cdac-73e08c673c6f"
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "uNum = df.uid.max() + 1\n",
    "vNum = df.vid.max() + 1\n",
    "tNum = df.tid.max() + 1\n",
    "maxVenue = 5\n",
    "latent_dim = 10\n",
    "nb_epochs = 1\n",
    "\n",
    "rec = Recommender(uNum, vNum, tNum, latent_dim, maxVenue)\n",
    "\n",
    "for epoch in range(nb_epochs):\n",
    "    X = generate_training_instances()\n",
    "    y = np.array([1]*len(X[0]))\n",
    "    rec.model.fit(X, y, nb_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jucmvpdhWIAK"
   },
   "outputs": [],
   "source": [
    "def generate_testing_instances(uid, target_timestamp, candidate_venues):\n",
    "    x_times, x_time_intervals, x_pos_checkins, x_neg_checkins, x_pos_distances, x_neg_distances = [], [], [], [], [], []\n",
    "    group = df[df.uid == uid]\n",
    "    visits = group.vid.tolist()\n",
    "    lats = group.lat.tolist()\n",
    "    lngs = group.lng.tolist()\n",
    "    times = group.tid.tolist()\n",
    "\n",
    "    tid = time_encoder(target_timestamp)\n",
    "\n",
    "    timestamp = group.time.tolist()\n",
    "    pos_distances = [0] + [get_distance(lats[i], lngs[i], lats[i + 1], lngs[i + 1]) for i in range(len(visits) - 1)]\n",
    "    time_intervals = [0] + [get_time_interval(timestamp[i], timestamp[i + 1]) for i in range(len(timestamp) - 1)]\n",
    "\n",
    "    for j in candidate_venues:\n",
    "        sub_checkins = visits + [j]\n",
    "        sub_times = times + [tid]\n",
    "        sub_time_intervals = time_intervals + [get_time_interval(timestamp[-1], target_timestamp)]\n",
    "\n",
    "        j_coor = vid2latlng[j]\n",
    "        sub_distances = pos_distances + [get_distance(lats[-1], lngs[-1], j_coor[0], j_coor[1])]\n",
    "\n",
    "        x_times.extend(sequence.pad_sequences([sub_times[:]], maxlen=maxVenue))\n",
    "        x_pos_checkins.extend(sequence.pad_sequences([sub_checkins[:]], maxlen=maxVenue))\n",
    "        x_pos_distances.extend(\n",
    "                np.expand_dims(sequence.pad_sequences([sub_distances[:]], maxlen=maxVenue), -1))\n",
    "        x_time_intervals.extend(\n",
    "                np.expand_dims(sequence.pad_sequences([sub_time_intervals[:]], maxlen=maxVenue), -1))\n",
    "\n",
    "    \n",
    "    return np.array(x_times), np.array(x_time_intervals), np.array(x_pos_distances), np.array(x_pos_checkins)\n",
    "\n",
    "target_uid = 1\n",
    "target_timestamp = \"2010-10-17T01:48:53Z\"\n",
    "candidate_venues = [1, 2, 3, 4, 5]\n",
    "x_times, x_time_intervals, x_distances, x_checkins = generate_testing_instances(target_uid, target_timestamp, candidate_venues)\n",
    "\n",
    "# predicted score for each candidate venue\n",
    "scores = rec.rank(target_uid, x_checkins, x_times, x_time_intervals, x_distances)\n",
    "print(scores)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CARA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
